---
# Source: harbor/charts/postgresql/templates/secrets.yaml

apiVersion: v1
kind: Secret
metadata:
  name: release-name-postgresql
  labels:
    app: postgresql
    chart: postgresql-7.7.3
    release: "release-name"
    heritage: "Tiller"
type: Opaque
data:
  postgresql-password: "bm90LXNlY3VyZS1kYXRhYmFzZS1wYXNzd29yZA=="
  postgresql-replication-password: "cmVwbF9wYXNzd29yZA=="
---
# Source: harbor/templates/chartmuseum/chartmuseum-secret.yaml

apiVersion: v1
kind: Secret
metadata:
  name: "release-name-harbor-chartmuseum-secret"
  labels: 
    app.kubernetes.io/name: "harbor"
    helm.sh/chart: "harbor-3.0.2"
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Tiller
    app.kubernetes.io/component: chartmuseum
type: Opaque
data:
  CACHE_REDIS_PASSWORD: ""

---
# Source: harbor/templates/core/core-secret-envvars.yaml
apiVersion: v1
kind: Secret
metadata:
  name: release-name-harbor-core-envvars
  labels: 
    app.kubernetes.io/name: "harbor"
    helm.sh/chart: "harbor-3.0.2"
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Tiller
type: Opaque
data:
  HARBOR_ADMIN_PASSWORD: "aGFyYm9y"
  POSTGRESQL_PASSWORD: "bm90LXNlY3VyZS1kYXRhYmFzZS1wYXNzd29yZA=="
  CLAIR_DB_PASSWORD: "bm90LXNlY3VyZS1kYXRhYmFzZS1wYXNzd29yZA=="
---
# Source: harbor/templates/core/core-secret.yaml
apiVersion: v1
kind: Secret
metadata:
  name: "release-name-harbor-core"
  labels: 
    app.kubernetes.io/name: "harbor"
    helm.sh/chart: "harbor-3.0.2"
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Tiller
type: Opaque
data:
  secretKey: "bm90LWEtc2VjdXJlLWtleQ=="
  secret: "ajlhcHY0d2o5bWF2NDR1OThwYXY0YW04OWF2NA=="
  tls.crt: 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
  tls.key: LS0tLS1CRUdJTiBSU0EgUFJJVkFURSBLRVktLS0tLQpNSUlKS0FJQkFBS0NBZ0VBcW9HOGZzbndDcGYrbVdZN29qeFRDcWFzTlZ1RFF2ODRrbGoxR2tNN2RKRk5WcDBKClc1dVpJWlIrdnVEcTRWSXV2cWVldWNPOUYxeE1hRmhHcWZWaWJ1ZXdFRDJvV0k0WTJLbTMrVDlhMHI2dEZLYWoKYUl5cDU3T0hYeXNYY2hPSjh6eXRkbGFuZGlpOHpQQWEvbEgwYmpPR0d5Yk5OTVo5RWtzRG5OWE05WUxQOTVESApqc0hSdW9JdDVpUW9JSlhxaGFvL0RFd2FCY2R4V0tPK3dTRUZuZU8wTklpaXl0dlRodTRsNmg4RE5WRFh4c1AwCnNqN2R2VmVxWTEwYzFERDNKSytaNTByTllsNUI5NVdIZlRrbU5zSEpsYjh2MXN0OXQ5OHkzNCtNa0RNR1FKS08KWGVRUEx3Q0RLSW1MN253eStjalVpSGx3RVkzOWxFQWM3QVVsNFFGd2pTMzhSMVo5SzVOS3dRYkFNdUxpVWVJbQp5OFZGbzE0Yy9BbExFOXFIWkxxMzhiRmhlSm9CeWk4b1k0NmU2Q1dKVE1Uc2ZybGdWV0dTQ1VvT21wQzNGZitsCnVDVStwdGZrRkh6MmxRdVZNaitVN3ZSa2dLZ3JxdG9tSklQc3FvS3cxd0tRcG9YOWtqblVDcHRnNEdtOHNOL1IKTDlJZUJJQnhkV1hsZS9nbGZNT1IvV25rVWdhanNqN21YZ2d0M3I5bklUaDZaUk1ZU1I1dXZjRDNldWwrYm1YRQpuMXFmOVdXQ1FKR2c2K0R6YnVsOFUwMC9zc3RpYWtvT0hETHN0OEhhWnkxTmZOUlBtN1lOVmd1eXFyNm9YNENPCm9uTTRtNnlib0YralBMQ3VmWFU2RWF2VDNFNEtBUzRSaFRzb3dqYzByL3BDU2ZOZGM3RU9EMWJucHQwQ0F3RUEKQVFLQ0FnQVUvalk4RWhibzV2L2syUzU4Y2hyelU4UWVLYTlHbjIvU3JQczRpWkNYY0pCcUdwbWRXdElHeldheApqN1c3bWtmQkY1ZzJYUUE2RVJZalBzTXNoOWJmdXN6MW92SElQVzZYdG9XOVBXeXNSK2U5aENyWVk0RkQwdG5YCkFOSTVMR2l1dHdqUWFpamlKbS9nZDZ1TEpvSUcwM2N1ZnArRFlQRGpRTE1vS3phNS82b2xYQUVGOVowaDdvZEMKTDY5MUc2QXRadUd1WE94VFM5UUx5dFZncC9VdUZHd0tqOHdqVjk5NlhIWDBsbTdwc0pOd21JM1hLR0Jhd0tGcwo3SGp4TXpvcW5TaEF6dmZzcFpoUHFHeHZJWXN2OExvbUlzejhFRC9oVkt6SjA3M0Z2MUtFdnNhaWpzTEQwYmRVClZXTVNNTjZCM0pVMlhHVk05QU9GcmtNaFdCenFuS2ZSM3FubXRoWTk1RG1nNWM1T0pPQW5pWTZDelZyL0xaemUKRnk3WXA2ZGhvK0dGZDJpT28wTGJvaVVWcytxUG9MUkdpYURpc1ZpQ1c3NG1Eait1YXZzeDBGTmFsV09KM29aYgpRUWZjQzJFRVJjSUpGZUlVeG55a3B5dnNxOW1SNm5sSkE1bTBVWEwreVRwK2l4R1NrTXg3aEd4azdXNGlJK1RFCjdTWWtkcE1wckR0TmQ0NkNDcEVqTDRjcDN3S3FPODNESFpiUmlJQlc0TG5tdjgvRmsxMzl4ZmFWS1UxYThPejYKZUl2N1NBakppQ1Zwaml6N1cyWHZGSU02R0lkaXZxSjV0ZURIVUtWZ2JnSFZWWFd6ZTlGTGZVbldlNnhYeGs3UAo3d0FqaFBBOEtNWDAvU2tOTzlzQ284TzBiVkxnbWhRVFpQZWRCbjQvaVZqais2M1BRUUtDQVFFQTJwbXZLakRuCk1kT3FLdzdjdXNXR0IwTHRkeHpnWXQ4RVZYRnFjZHdRSWs4ajJiams5VGZnR3NlQW1BZnd2bCtwbXoyNDlLSGEKOTk1RmpPU01JZ0FCQUE3MWxWQ1ZQZ1MrOVk4NWVnbXlxNmpVcW1kbHJyWlBpQW00RE85UXo2eElGSlRmTEUxawpXajhlZW9PNkVxTWloN21RMGtrK3g0aEJTRS9QRWJxak1ZRE9OcTd3dWtwNG5WLzJ4eUxSVEFrejhkellRNEVxCjVVSEFlSDZXVVJSTTROY1IveHNaeDFXZzBZZU1QY3lGdy96KzlnUzR2cDlZNkdhangvOVByQWhmSmNpcE0vcTgKRDZaQWZpSCtsbW0yb0IzeGQyUUtHN0JZN1pJeHgvZDRSemtsb0FVaTlraG10c21mSTk1LzVPNjVuWTU0QnZJVwpGQ0JWNEg4ekxueEhzUUtDQVFFQXg2MmpWbUtxcXpjUnR5OHloU3ptVHdCK1dRUkN3MVRPU1d3WCs1aUVpMk9sClVQUVgxMm9vU1Y5UXdxb004S203Z0g2dVR1WGw5aUs3eDVjZzBmWEV5WDJ1NmVZZzhjRm1vUC91V2l0UndpVnIKclNjNlJyQzlwNy9ndVRWUElIWmo0MTBPSE15aTNqSGRlL01rT2UzaDJVa3kzcHhNZTNjcEJ6NTJoUTQxem4zWApSa1BLOUJFM2NoeE41VVd0dVk1dlpYSTFEYWlqYjkxWHlac0VZM2RFSklYeTJVOVovS3MvSjJIdDdRV2NwblpuClNyZHFPQitPa25Qb2NPcHo5R1ZtZVRIdThyMkpyWUxXanUrMWhIc1ZRY09YU3hWWWZnV1k3Ulc3OG9CUlBpamgKSk81eHEvNXNWR1Ywa3o4Si8rdmN1VnFwd0dScG5QUWxGOFVxUUFmSTdRS0NBUUVBaDNQTlQyWm9DNzd0WmFyYQo2VHgxdFZBcVZyRms5TDdlTDVlTWJxcitzRk83a2pCNFp0NU5saXBpcTFIWVFnNkN5UGZ4QUZ5K2t2Sit4RFBtCkJUZGRaMHpkcmJ6MkRTemhxc1VweDAzMUVWc1hFOVBuOU45dzNvbXZLd3lyVlZPYWdtNVE3Mkd4T2g1OFkwdjIKWTVBRVdIZUtubExXZk1zWU1KZUxacC93ZVQ4b0NFaFVVQXJQUEN6M2ZDTTk3MUNRaUdEZy9Nc3Y2a2pZMjVFTQowWWF6c0dwejgxQTJwQWFTRk9OWjZmMHVNZWcxai9vVEE4TTNVeUl1Z0VIYWUyM2dqMGdNV0hJWVQ5WWpoa1RJClBTbWFDUk1reVdjS3dHZUFZdzFBblhqaFpiaXFjTUplREorR1RlTVhJaUcvdS9xVXQyVk5TSGgvWjg4MWgxc3EKT3JhMXNRS0NBUUJJd2ZScVhibGllY1p5d1RmZlh1VHNsSGwxWmlBTm5MRXQvNzBkYUEyajNNTTRKRGtydlByQgpBWUlqN0dLYXJyNHJxLzFIc20yQXFsZFIrcmR5eWVMU3FJRTdxU2NIOERpOUlZUndScWliM1piR21TeWE1WHUxCnpDek9UNlp0WmJZditwQlIzaDdhWjhFVWtSdjZIN3ZUdU9CWVRRdHhVWklabWFFR0NvK0Fsa29DeUdFRFhlS2UKS2NJWWNMTkVrYW4xaFEvZjBqcjdYK1BGQ2o4bkh5WXRTTUdjZlZXRXc4RlhVRStwdGduR2ZnNVZJMUFJOHphNApGcFB6MFBvL2ExTlRoZVpUZk16VjlIN0p4bjZWcjJPbmV1Vjk3bUU0U2tIVzRieUNPRTlpSHZNcXlkZVJuRHRNCjVVcjgvRk5nZFVrUUlRRUpvWXo2Szl2NE5WZVh6VDVoQW9JQkFBb0x0eXI0R2ZONE44eTNXRngwcVZXSWVLcm8Kem5USjNEOW5HYkdTS1pERlRQTmI4blBmWTlLTko1R0hhTHJWWkxnQ3Z1TmtSbWh5OERFNXkwNitEZ2xjQS9ERQp0VHgzdTNvb3ZqNHVBdW1OK2dxR0JLRDZWQ0c1amN1SHZlcUliRGZzbDFaWXlTa2s0MCtjZkVseUN0b01MNUpaCkdLVFlTWi9ReTRDeG1LV1FjYkhBMTJvRXAvWWJPc1cwakxTbk1WREY1VDYyRlY2UkdaL2FkYmFQejYvYm9LQ1kKdEx0cTkzUHhtaFVkMWVaempvZHljRU8zMk5wVnk3T0NYWlhocnZBWmV6Zkp5dDcxcVh6UUhZVWxMQ1BVa2YvZQpDN0l3R2FETUlxNGdCKzFVUDd6bHhXVUlFTnFUVlREZzdVNitCdlhvS3cyZTd3eU4xc1lsOS96UXJvST0KLS0tLS1FTkQgUlNBIFBSSVZBVEUgS0VZLS0tLS0K
---
# Source: harbor/templates/jobservice/jobservice-secrets.yaml
apiVersion: v1
kind: Secret
metadata:
  name: "release-name-harbor-jobservice"
  labels: 
    app.kubernetes.io/name: "harbor"
    helm.sh/chart: "harbor-3.0.2"
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Tiller
type: Opaque
data:
  secret: "d1o1UG5pMWVjNnpWU2w4SQ=="

---
# Source: harbor/templates/registry/registry-secret.yaml
apiVersion: v1
kind: Secret
metadata:
  name: "release-name-harbor-registry"
  labels: 
    app.kubernetes.io/name: "harbor"
    helm.sh/chart: "harbor-3.0.2"
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Tiller
type: Opaque
data:
  REGISTRY_HTTP_SECRET: "MUFsNzNiZUNObmw5b05rbw=="
  REGISTRY_REDIS_PASSWORD: ""

---
# Source: harbor/charts/postgresql/templates/initialization-configmap.yaml

apiVersion: v1
kind: ConfigMap
metadata:
  name: release-name-postgresql-init-scripts
  labels:
    app: postgresql
    chart: postgresql-7.7.3
    release: "release-name"
    heritage: "Tiller"
data:
  initial-notaryserver.sql: |
    CREATE DATABASE notaryserver;
    CREATE USER server;
    alter user server with encrypted password 'password';
    GRANT ALL PRIVILEGES ON DATABASE notaryserver TO server;
  initial-notarysigner.sql: |
    CREATE DATABASE notarysigner;
    CREATE USER signer;
    alter user signer with encrypted password 'password';
    GRANT ALL PRIVILEGES ON DATABASE notarysigner TO signer;
  initial-registry.sql: |
    CREATE DATABASE registry ENCODING 'UTF8';
    \c registry;
    CREATE TABLE schema_migrations(version bigint not null primary key, dirty boolean not null);
  

---
# Source: harbor/charts/redis/templates/configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: release-name-redis
  labels:
    app: redis
    chart: redis-9.5.5
    heritage: Tiller
    release: release-name
data:
  redis.conf: |-
    # User-supplied configuration:
    # Enable AOF https://redis.io/topics/persistence#append-only-file
    appendonly yes
    # Disable RDB persistence, AOF persistence already enabled.
    save ""
  master.conf: |-
    dir /data
    rename-command FLUSHDB ""
    rename-command FLUSHALL ""
  replica.conf: |-
    dir /data
    slave-read-only yes
    rename-command FLUSHDB ""
    rename-command FLUSHALL ""

---
# Source: harbor/charts/redis/templates/health-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: release-name-redis-health
  labels:
    app: redis
    chart: redis-9.5.5
    heritage: Tiller
    release: release-name
data:
  ping_readiness_local.sh: |-
    response=$(
      timeout -s 9 $1 \
      redis-cli \
        -h localhost \
        -p $REDIS_PORT \
        ping
    )
    if [ "$response" != "PONG" ]; then
      echo "$response"
      exit 1
    fi
  ping_liveness_local.sh: |-
    response=$(
      timeout -s 9 $1 \
      redis-cli \
        -h localhost \
        -p $REDIS_PORT \
        ping
    )
    if [ "$response" != "PONG" ] && [ "$response" != "LOADING Redis is loading the dataset in memory" ]; then
      echo "$response"
      exit 1
    fi
  ping_readiness_master.sh: |-
    response=$(
      timeout -s 9 $1 \
      redis-cli \
        -h $REDIS_MASTER_HOST \
        -p $REDIS_MASTER_PORT_NUMBER \
        ping
    )
    if [ "$response" != "PONG" ]; then
      echo "$response"
      exit 1
    fi
  ping_liveness_master.sh: |-
    response=$(
      timeout -s 9 $1 \
      redis-cli \
        -h $REDIS_MASTER_HOST \
        -p $REDIS_MASTER_PORT_NUMBER \
        ping
    )
    if [ "$response" != "PONG" ] && [ "$response" != "LOADING Redis is loading the dataset in memory" ]; then
      echo "$response"
      exit 1
    fi
  ping_readiness_local_and_master.sh: |-
    script_dir="$(dirname "$0")"
    exit_status=0
    "$script_dir/ping_readiness_local.sh" $1 || exit_status=$?
    "$script_dir/ping_readiness_master.sh" $1 || exit_status=$?
    exit $exit_status
  ping_liveness_local_and_master.sh: |-
    script_dir="$(dirname "$0")"
    exit_status=0
    "$script_dir/ping_liveness_local.sh" $1 || exit_status=$?
    "$script_dir/ping_liveness_master.sh" $1 || exit_status=$?
    exit $exit_status

---
# Source: harbor/templates/chartmuseum/chartmuseum-cm-envvars.yaml

apiVersion: v1
kind: ConfigMap
metadata:
  name: "release-name-harbor-chartmuseum-envvars"
  labels:  
    app.kubernetes.io/name: "harbor"
    helm.sh/chart: "harbor-3.0.2"
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Tiller
    app.kubernetes.io/component: chartmuseum
data:
  PORT: "8080"
  CACHE: "redis"
  CACHE_REDIS_ADDR: "release-name-redis-master:6379"
  CACHE_REDIS_DB: "3"
  # The user is hardcoded because the core binary has it hardcoded so it is not configurable.
  BASIC_AUTH_USER: "chart_controller"
  DEPTH: "1"
  DEBUG: "1"
  LOG_JSON: "false"
  DISABLE_METRICS: "false"
  DISABLE_API: "false"
  DISABLE_STATEFILES: "false"
  ALLOW_OVERWRITE: "true"
  AUTH_ANONYMOUS_GET: "false"
  STORAGE: "local"
  STORAGE_LOCAL_ROOTDIR: "/bitnami/data"

---
# Source: harbor/templates/clair/clair-cm.yaml

apiVersion: v1
kind: ConfigMap
metadata:
  name: "release-name-harbor-clair"
  labels: 
    app.kubernetes.io/name: "harbor"
    helm.sh/chart: "harbor-3.0.2"
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Tiller
    app.kubernetes.io/component: clair
data:
  config.yaml: |
    clair:
      database:
        type: pgsql
        options:
          source: "postgres://postgres:not-secure-database-password@release-name-postgresql:5432/postgres?sslmode=disable"
          # Number of elements kept in the cache
          # Values unlikely to change (e.g. namespaces) are cached in order to save prevent needless roundtrips to the database.
          cachesize: 16384

      api:
        # API server port
        port: 6060
        healthport: 6061

        # Deadline before an API request will respond with a 503
        timeout: 300s
      updater:
        interval: 12h

      notifier:
        attempts: 3
        renotifyinterval: 2h
        http:
          endpoint: "http://release-name-harbor-core/service/notifications/clair"

---
# Source: harbor/templates/core/core-cm-envvars.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: release-name-harbor-core-envvars
  labels: 
    app.kubernetes.io/name: "harbor"
    helm.sh/chart: "harbor-3.0.2"
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Tiller
data:
  DATABASE_TYPE: "postgresql"
  POSTGRESQL_HOST: "release-name-postgresql"
  POSTGRESQL_PORT: "5432"
  POSTGRESQL_USERNAME: "postgres"
  POSTGRESQL_DATABASE: "registry"
  POSTGRESQL_SSLMODE: "disable"
  EXT_ENDPOINT: "https://registry.baloise.dev"
  CORE_URL: "http://release-name-harbor-core"
  JOBSERVICE_URL: "http://release-name-harbor-jobservice"
  REGISTRY_URL: "http://release-name-harbor-registry:5000"
  TOKEN_SERVICE_URL: "http://release-name-harbor-core/service/token"
  WITH_NOTARY: "false"
  NOTARY_URL: "http://release-name-harbor-notary-server:4443"
  CFG_EXPIRATION: "5"
  ADMIRAL_URL: "NA"
  WITH_CLAIR: "true"
  CLAIR_DB_HOST: "release-name-postgresql"
  CLAIR_DB_PORT: "5432"
  CLAIR_DB_USERNAME: "postgres"
  CLAIR_DB: "postgres"
  CLAIR_DB_SSLMODE: "disable"
  CLAIR_URL: "http://release-name-harbor-clair:6060"
  REGISTRY_STORAGE_PROVIDER_NAME: "filesystem"
  WITH_CHARTMUSEUM: "true"
  CHART_REPOSITORY_URL: "http://release-name-harbor-chartmuseum"
  LOG_LEVEL: "debug"
  CONFIG_PATH: "/etc/core/app.conf"
  SYNC_REGISTRY: "false"
  CHART_CACHE_DRIVER: "redis"
  _REDIS_URL: "release-name-redis-master:6379,100,"
  _REDIS_URL_REG: "redis://release-name-redis-master:6379/2"
  PORTAL_URL: "http://release-name-harbor-portal"
  REGISTRYCTL_URL: "http://release-name-harbor-registry:8080"
  CLAIR_HEALTH_CHECK_SERVER_URL: "http://release-name-harbor-clair:6061"

---
# Source: harbor/templates/core/core-cm.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: "release-name-harbor-core"
  labels: 
    app.kubernetes.io/name: "harbor"
    helm.sh/chart: "harbor-3.0.2"
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Tiller
data:
  app.conf: |+
    appname = Harbor
    runmode = dev
    enablegzip = true

    [dev]
    httpport = 8080
---
# Source: harbor/templates/jobservice/jobservice-cm.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: "release-name-harbor-jobservice"
  labels: 
    app.kubernetes.io/name: "harbor"
    helm.sh/chart: "harbor-3.0.2"
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Tiller
data:
  config.yml: |+
    protocol: "http"
    port: 8080
    worker_pool:
      workers: 10
      backend: "redis"
      redis_pool:
        redis_url: "release-name-redis-master:6379/1"
        namespace: "harbor_job_service_namespace"
    job_loggers:
      - name: "FILE"
        level: DEBUG
        settings: # Customized settings of logger
          base_dir: "/var/log/jobs"
        sweeper:
          duration: 14 #days
          settings: # Customized settings of sweeper
            work_dir: "/var/log/jobs"
    #Loggers for the job service
    loggers:
      - name: "STD_OUTPUT"
        level: DEBUG
---
# Source: harbor/templates/nginx/configmap-http.yaml

apiVersion: v1
kind: ConfigMap
metadata:
  name: "release-name-harbor-nginx"
  labels: 
    app.kubernetes.io/name: "harbor"
    helm.sh/chart: "harbor-3.0.2"
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Tiller
data:
  nginx.conf: |+
    worker_processes auto;

    events {
      worker_connections 1024;
      use epoll;
      multi_accept on;
    }

    http {
      tcp_nodelay on;

      # this is necessary for us to be able to disable request buffering in all cases
      proxy_http_version 1.1;

      upstream core {
        server release-name-harbor-core;
      }

      upstream portal {
        server release-name-harbor-portal;
      }

      log_format timed_combined '$remote_addr - '
        '"$request" $status $body_bytes_sent '
        '"$http_referer" "$http_user_agent" '
        '$request_time $upstream_response_time $pipe';

      access_log /dev/stdout timed_combined;

      client_body_temp_path  "/opt/bitnami/nginx/tmp/client_body" 1 2;
      proxy_temp_path        "/opt/bitnami/nginx/tmp/proxy" 1 2;
      fastcgi_temp_path      "/opt/bitnami/nginx/tmp/fastcgi" 1 2;
      scgi_temp_path         "/opt/bitnami/nginx/tmp/scgi" 1 2;
      uwsgi_temp_path        "/opt/bitnami/nginx/tmp/uwsgi" 1 2;

      server {
        listen 8080;
        server_tokens off;
        # disable any limits to avoid HTTP 413 for large image uploads
        client_max_body_size 0;

        location / {
          proxy_pass http://portal/;
          proxy_set_header Host $host;
          proxy_set_header X-Real-IP $remote_addr;
          proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;

          proxy_buffering off;
          proxy_request_buffering off;
        }

        location /api/ {
          proxy_pass http://core/api/;
          proxy_set_header Host $host;
          proxy_set_header X-Real-IP $remote_addr;
          proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;

          proxy_buffering off;
          proxy_request_buffering off;
        }

        location /chartrepo/ {
          proxy_pass http://core/chartrepo/;
          proxy_set_header Host $host;
          proxy_set_header X-Real-IP $remote_addr;
          proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;

          proxy_buffering off;
          proxy_request_buffering off;
        }

        location /c/ {
          proxy_pass http://core/c/;
          proxy_set_header Host $host;
          proxy_set_header X-Real-IP $remote_addr;
          proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;

          proxy_buffering off;
          proxy_request_buffering off;
        }

        location /v1/ {
          return 404;
        }

        location /v2/ {
          proxy_pass http://core/v2/;
          proxy_set_header Host $http_host;
          proxy_set_header X-Real-IP $remote_addr;
          proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;

          proxy_buffering off;
          proxy_request_buffering off;
        }

        location /service/ {
          proxy_pass http://core/service/;
          proxy_set_header Host $host;
          proxy_set_header X-Real-IP $remote_addr;
          proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;

          proxy_buffering off;
          proxy_request_buffering off;
        }

      location /service/notifications {
          return 404;
        }
      }
    }

---
# Source: harbor/templates/registry/registry-cm.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: "release-name-harbor-registry"
  labels: 
    app.kubernetes.io/name: "harbor"
    helm.sh/chart: "harbor-3.0.2"
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Tiller
data:
  config.yml: |+
    version: 0.1
    log:
      level: debug
      fields:
        service: registry
    storage:
      filesystem:
        rootdirectory: /storage
      cache:
        layerinfo: redis
      maintenance:
        uploadpurging:
          enabled: false
      delete:
        enabled: true
      redirect:
        disable: true
    redis:
      addr: "release-name-redis-master:6379"
      db: 2
    http:
      addr: :5000
      relativeurls: true
      # set via environment variable
      # secret: placeholder
      debug:
        addr: localhost:5001
    auth:
      token:
        issuer: harbor-token-issuer
        realm: "https://registry.baloise.dev/service/token"
        rootcertbundle: /etc/registry/root.crt
        service: harbor-registry
    validation:
      disabled: true
    notifications:
      endpoints:
        - name: harbor
          disabled: false
          url: http://release-name-harbor-core/service/notifications
          timeout: 3000ms
          threshold: 5
          backoff: 1s
  ctl-config.yml: |+
    ---
    protocol: "http"
    port: 8080
    log_level: debug

---
# Source: harbor/templates/chartmuseum/chartmuseum-pvc.yaml

kind: PersistentVolumeClaim
apiVersion: v1
metadata:
  name: release-name-harbor-chartmuseum
  annotations:
    helm.sh/resource-policy: keep
  labels: 
    app.kubernetes.io/name: "harbor"
    helm.sh/chart: "harbor-3.0.2"
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Tiller
    app.kubernetes.io/component: chartmuseum
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 10Gi
  

---
# Source: harbor/templates/jobservice/jobservice-pvc.yaml

kind: PersistentVolumeClaim
apiVersion: v1
metadata:
  name: "release-name-harbor-jobservice"
  annotations:
    helm.sh/resource-policy: keep
  labels:
    app.kubernetes.io/name: "harbor"
    helm.sh/chart: "harbor-3.0.2"
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Tiller
    app.kubernetes.io/component: jobservice
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 1Gi
  

---
# Source: harbor/templates/registry/registry-pvc.yaml

kind: PersistentVolumeClaim
apiVersion: v1
metadata:
  name: "release-name-harbor-registry"
  annotations:
    helm.sh/resource-policy: keep
  labels:
    app.kubernetes.io/name: "harbor"
    helm.sh/chart: "harbor-3.0.2"
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Tiller
    app.kubernetes.io/component: registry
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 30Gi
  

---
# Source: harbor/charts/postgresql/templates/svc-headless.yaml
apiVersion: v1
kind: Service
metadata:
  name: release-name-postgresql-headless
  labels:
    app: postgresql
    chart: postgresql-7.7.3
    release: "release-name"
    heritage: "Tiller"
spec:
  type: ClusterIP
  clusterIP: None
  ports:
    - name: postgresql
      port: 5432
      targetPort: postgresql
  selector:
    app: postgresql
    release: "release-name"

---
# Source: harbor/charts/postgresql/templates/svc-read.yaml

apiVersion: v1
kind: Service
metadata:
  name: release-name-postgresql-read
  labels:
    app: postgresql
    chart: postgresql-7.7.3
    release: "release-name"
    heritage: "Tiller"
spec:
  type: ClusterIP
  ports:
    - name: postgresql
      port:  5432
      targetPort: postgresql
  selector:
    app: postgresql
    release: "release-name"
    role: slave

---
# Source: harbor/charts/postgresql/templates/svc.yaml
apiVersion: v1
kind: Service
metadata:
  name: release-name-postgresql
  labels:
    app: postgresql
    chart: postgresql-7.7.3
    release: "release-name"
    heritage: "Tiller"
spec:
  type: ClusterIP
  ports:
    - name: postgresql
      port: 5432
      targetPort: postgresql
  selector:
    app: postgresql
    release: "release-name"
    role: master

---
# Source: harbor/charts/redis/templates/headless-svc.yaml
apiVersion: v1
kind: Service
metadata:
  name: release-name-redis-headless
  labels:
    app: redis
    chart: redis-9.5.5
    release: release-name
    heritage: Tiller
spec:
  type: ClusterIP
  clusterIP: None
  ports:
  - name: redis
    port: 6379
    targetPort: redis
  selector:
    app: redis
    release: release-name

---
# Source: harbor/charts/redis/templates/redis-master-svc.yaml

apiVersion: v1
kind: Service
metadata:
  name: release-name-redis-master
  labels:
    app: redis
    chart: redis-9.5.5
    release: release-name
    heritage: Tiller
spec:
  type: ClusterIP
  ports:
  - name: redis
    port: 6379
    targetPort: redis
  selector:
    app: redis
    release: release-name
    role: master

---
# Source: harbor/charts/redis/templates/redis-slave-svc.yaml

apiVersion: v1
kind: Service
metadata:
  name: release-name-redis-slave
  labels:
    app: redis
    chart: redis-9.5.5
    release: release-name
    heritage: Tiller
spec:
  type: ClusterIP
  ports:
  - name: redis
    port: 6379
    targetPort: redis
  selector:
    app: redis
    release: release-name
    role: slave

---
# Source: harbor/templates/chartmuseum/chartmuseum-svc.yaml

apiVersion: v1
kind: Service
metadata:
  name: "release-name-harbor-chartmuseum"
  labels: 
    app.kubernetes.io/name: "harbor"
    helm.sh/chart: "harbor-3.0.2"
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Tiller
    app.kubernetes.io/component: chartmuseum
spec:
  ports:
    - port: 80
      name: http
      targetPort: http
  selector: 
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/name: "harbor"
    app.kubernetes.io/component: chartmuseum

---
# Source: harbor/templates/clair/clair-svc.yaml

apiVersion: v1
kind: Service
metadata:
  name: "release-name-harbor-clair"
  labels: 
    app.kubernetes.io/name: "harbor"
    helm.sh/chart: "harbor-3.0.2"
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Tiller
    app.kubernetes.io/component: clair
spec:
  ports:
    - name: clair
      port: 6060
    - name: health
      port: 6061
  selector:
    
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/name: "harbor"
    app.kubernetes.io/component: clair

---
# Source: harbor/templates/core/core-svc.yaml
apiVersion: v1
kind: Service
metadata:
  name: "release-name-harbor-core"
  labels: 
    app.kubernetes.io/name: "harbor"
    helm.sh/chart: "harbor-3.0.2"
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Tiller
spec:
  ports:
    - name: http
      port: 80
      targetPort: http
  selector:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/name: "harbor"
    app.kubernetes.io/component: core

---
# Source: harbor/templates/jobservice/jobservice-svc.yaml
apiVersion: v1
kind: Service
metadata:
  name: "release-name-harbor-jobservice"
  labels: 
    app.kubernetes.io/name: "harbor"
    helm.sh/chart: "harbor-3.0.2"
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Tiller
spec:
  ports:
    - name: http
      port: 80
      targetPort: http
  selector:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/name: "harbor"
    app.kubernetes.io/component: jobservice

---
# Source: harbor/templates/nginx/service.yaml

apiVersion: v1
kind: Service
metadata:
  name: harbor
  labels: 
    app.kubernetes.io/name: "harbor"
    helm.sh/chart: "harbor-3.0.2"
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Tiller
spec:
  type: ClusterIP
  ports:
    - name: http
      port: 80
      targetPort: 8080
  selector:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/name: "harbor"
    app.kubernetes.io/component: nginx

---
# Source: harbor/templates/portal/portal-svc.yaml
apiVersion: v1
kind: Service
metadata:
  name: "release-name-harbor-portal"
  labels: 
    app.kubernetes.io/name: "harbor"
    helm.sh/chart: "harbor-3.0.2"
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Tiller
spec:
  ports:
    - name: http
      port: 80
      targetPort: http
  selector:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/name: "harbor"
    app.kubernetes.io/component: portal

---
# Source: harbor/templates/registry/registry-svc.yaml
apiVersion: v1
kind: Service
metadata:
  name: "release-name-harbor-registry"
  labels: 
    app.kubernetes.io/name: "harbor"
    helm.sh/chart: "harbor-3.0.2"
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Tiller
spec:
  ports:
    - name: registry
      port: 5000
    - name: controller
      port: 8080
  selector:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/name: "harbor"
    app.kubernetes.io/component: registry
---
# Source: harbor/templates/chartmuseum/chartmuseum-dpl.yaml

apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  annotations:
  name: "release-name-harbor-chartmuseum"
  labels: 
    app.kubernetes.io/name: "harbor"
    helm.sh/chart: "harbor-3.0.2"
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Tiller
    app.kubernetes.io/component: chartmuseum
spec:
  replicas: 1
  selector:
    matchLabels:
      
      app.kubernetes.io/instance: release-name
      app.kubernetes.io/name: "harbor"
      app.kubernetes.io/component: chartmuseum
  template:
    metadata:
      labels:
        
        app.kubernetes.io/instance: release-name
        app.kubernetes.io/name: "harbor"
        app.kubernetes.io/component: chartmuseum
      annotations:
        checksum/configmap-envvars: a8afe119e9a21bda4fe64ef05ecdde2a2d231b8d21c7748735552b8ab2ff1603
        checksum/secret: bcb94eab3a6d585f77c10a0f3e64cf7fa41559afac51b1f987caec7ed40aab44
        checksum/secret-core: 9c5d57436694fb2b3e05ab1ad1188126482f6d4cb88c6b1211866be5032d7632
    spec:      
      securityContext:
        fsGroup: 1000090000
        runAsUser: 1000090000
      containers:
      - name: chartmuseum
        image: "docker.io/bitnami/chartmuseum:0.9.0-debian-9-r98"
        imagePullPolicy: "IfNotPresent"
        livenessProbe:
          httpGet:
            path: /health
            port: http
          initialDelaySeconds: 30
          periodSeconds: 10
          timeoutSeconds: 20
          successThreshold: 1
          failureThreshold: 10
        readinessProbe:
          httpGet:
            path: /health
            port: http
          initialDelaySeconds: 30
          periodSeconds: 10
          timeoutSeconds: 20
          successThreshold: 1
          failureThreshold: 10
        envFrom:
        - configMapRef:
            name: "release-name-harbor-chartmuseum-envvars"
        - secretRef:
            name: "release-name-harbor-chartmuseum-secret"
        env:
        - name: DEBUG
          value: "0"
        - name: BASIC_AUTH_PASS
          valueFrom:
            secretKeyRef:
              # Take the password from the core component secret
              name: release-name-harbor-core
              key: secret
        ports:
        - containerPort: 8080
          name: http
        volumeMounts:
        - name: chartmuseum-data
          mountPath: /bitnami/data
      volumes:
      - name: chartmuseum-data
        persistentVolumeClaim:
          claimName: release-name-harbor-chartmuseum

---
# Source: harbor/templates/clair/clair-dpl.yaml

apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: "release-name-harbor-clair"
  labels: 
    app.kubernetes.io/name: "harbor"
    helm.sh/chart: "harbor-3.0.2"
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Tiller
    app.kubernetes.io/component: clair
spec:
  replicas: 1
  selector:
    matchLabels:
      
      app.kubernetes.io/instance: release-name
      app.kubernetes.io/name: "harbor"
      app.kubernetes.io/component: clair
  template:
    metadata:
      labels:
        
        app.kubernetes.io/name: "harbor"
        helm.sh/chart: "harbor-3.0.2"
        app.kubernetes.io/instance: release-name
        app.kubernetes.io/managed-by: Tiller
        app.kubernetes.io/component: clair
      annotations:
        sidecar.istio.io/inject: "true"
        checksum/configmap: 4ac58e155c7b724967bb9a2e2211ee023b3e4e50af1ff2ffb1ccf83f62e207bc
    spec:      
      containers:
      - name: clair
        image:  "docker.io/bitnami/harbor-clair:1.10.0-debian-9-r1"
        imagePullPolicy: "IfNotPresent"
        livenessProbe:
          httpGet:
            path: /health
            port: 6061
          initialDelaySeconds: 20
          periodSeconds: 10
          timeoutSeconds: 5
          successThreshold: 1
          failureThreshold: 6
        readinessProbe:
          httpGet:
            path: /health
            port: 6061
          initialDelaySeconds: 20
          periodSeconds: 10
          timeoutSeconds: 5
          successThreshold: 1
          failureThreshold: 6
        env:
        - name: BITNAMI_DEBUG
          value: "false"
        - name: NO_PROXY
          value: "release-name-harbor-registry,release-name-harbor-core"
        ports:
        - containerPort: 6060
        volumeMounts:
        - name: clair-config
          mountPath: /etc/clair/config.yaml
          subPath: config.yaml
      volumes:
      - name: clair-config
        configMap:
          name: "release-name-harbor-clair"
          items:
          - key: config.yaml
            path: config.yaml

---
# Source: harbor/templates/core/core-dpl.yaml
apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: "release-name-harbor-core"
  labels:
    app.kubernetes.io/name: "harbor"
    helm.sh/chart: "harbor-3.0.2"
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Tiller
    app.kubernetes.io/component: core
spec:
  replicas: 1
  selector:
    matchLabels: 
      app.kubernetes.io/instance: release-name
      app.kubernetes.io/name: "harbor"
      app.kubernetes.io/component: core
  template:
    metadata:
      labels:
        
        app.kubernetes.io/instance: release-name
        app.kubernetes.io/name: "harbor"
        app.kubernetes.io/component: core
      annotations:
        sidecar.istio.io/inject: "true"
        checksum/configmap: 422243aa72e61872c3f7b9c24d588ba3f6c03b305e9c377c288f35e69ad5a17d
        checksum/configmap-envvars: 270175d46f38dc72d79f2ab5061bf8a59d06afb45976408a921590394a17af99
        checksum/secret: 9c5d57436694fb2b3e05ab1ad1188126482f6d4cb88c6b1211866be5032d7632
        checksum/secret-envvars: 694ae640b63129917d30f0fc877ded4b7eb6688d82a61e1bcfeb38db5f9f6fe2
        checksum/secret-jobservice: d5f2d885a6cc4ed73c0083208dfdbd4d39eb029fc8815d47f86d13d11e4f624e
    spec:      
      securityContext:
        fsGroup: 1000090000
        runAsUser: 1000090000
      containers:
      - name: core
        image: "docker.io/bitnami/harbor-core:1.10.0-debian-9-r1"
        imagePullPolicy: "IfNotPresent"
        livenessProbe:
          httpGet:
            path: /api/ping
            port: http
          initialDelaySeconds: 20
          periodSeconds: 10
          timeoutSeconds: 5
          successThreshold: 1
          failureThreshold: 6
        readinessProbe:
          httpGet:
            path: /api/ping
            port: http
          initialDelaySeconds: 20
          periodSeconds: 10
          timeoutSeconds: 5
          successThreshold: 1
          failureThreshold: 6
        envFrom:
        - configMapRef:
            name: "release-name-harbor-core-envvars"
        - secretRef:
            name: "release-name-harbor-core-envvars"
        env:
        - name: BITNAMI_DEBUG
          value: "false"
        - name: CORE_SECRET
          valueFrom:
            secretKeyRef:
              name: "release-name-harbor-core"
              key: secret
        - name: JOBSERVICE_SECRET
          valueFrom:
            secretKeyRef:
              name: "release-name-harbor-jobservice"
              key: secret
        ports:
        - containerPort: 8080
          name: http
        volumeMounts:
        - name: config
          mountPath: /etc/core/app.conf
          subPath: app.conf
        - name: secret-key
          mountPath: /etc/core/key
          subPath: key
        - name: token-service-private-key
          mountPath: /etc/core/private_key.pem
          subPath: tls.key
        - name: psc
          mountPath: /etc/core/token
      volumes:
      - name: config
        configMap:
          name: "release-name-harbor-core"
          items:
            - key: app.conf
              path: app.conf
      - name: secret-key
        secret:
          secretName: "release-name-harbor-core"
          items:
            - key: secretKey
              path: key
      - name: token-service-private-key
        secret:
          secretName: "release-name-harbor-core"
      - name: psc
        emptyDir: {}

---
# Source: harbor/templates/jobservice/jobservice-dpl.yaml
apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: "release-name-harbor-jobservice"
  labels:
    app.kubernetes.io/name: "harbor"
    helm.sh/chart: "harbor-3.0.2"
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Tiller
    app.kubernetes.io/component: jobservice
spec:
  replicas: 1
  selector:
    matchLabels: 
      app.kubernetes.io/instance: release-name
      app.kubernetes.io/name: "harbor"
      app.kubernetes.io/component: jobservice
  template:
    metadata:
      labels:
        
        app.kubernetes.io/name: "harbor"
        helm.sh/chart: "harbor-3.0.2"
        app.kubernetes.io/instance: release-name
        app.kubernetes.io/managed-by: Tiller
        app.kubernetes.io/component: jobservice
      annotations:
        sidecar.istio.io/inject: "true"
        checksum/configmap: 8e54227e5b2458b8ae1989752e4738366f7dbed958e1eedcf58e2c7b07a0f096
        checksum/secret: c3eae656d0cf161d8e846a997ee22cc591402eb0f3753e6c708a5e7894780173
        checksum/secret-core: 9c5d57436694fb2b3e05ab1ad1188126482f6d4cb88c6b1211866be5032d7632
    spec:      
      securityContext:
        fsGroup: 1000090000
        runAsUser: 1000090000
      containers:
      - name: jobservice
        image: "docker.io/bitnami/harbor-jobservice:1.10.0-debian-9-r1"
        imagePullPolicy: "IfNotPresent"
        livenessProbe:
          httpGet:
            path: /api/v1/stats
            port: http
          initialDelaySeconds: 20
          periodSeconds: 10
          timeoutSeconds: 5
          successThreshold: 1
          failureThreshold: 6
        readinessProbe:
          httpGet:
            path: /api/v1/stats
            port: http
          initialDelaySeconds: 20
          periodSeconds: 10
          timeoutSeconds: 5
          successThreshold: 1
          failureThreshold: 6
        env:
        - name: BITNAMI_DEBUG
          value: "false"
        - name: CORE_SECRET
          valueFrom:
            secretKeyRef:
              name: "release-name-harbor-core"
              key: secret
        - name: JOBSERVICE_SECRET
          valueFrom:
            secretKeyRef:
              name: "release-name-harbor-jobservice"
              key: secret
        - name: CORE_URL
          value: "http://release-name-harbor-core"
        - name: REGISTRY_CONTROLLER_URL
          value: "http://release-name-harbor-registry:8080"
        - name: LOG_LEVEL
          value: debug
        ports:
        - containerPort: 8080
          name: http
        volumeMounts:
        - name: jobservice-config
          mountPath: /etc/jobservice/config.yml
          subPath: config.yml
        - name: job-logs
          mountPath: /var/log/jobs
          subPath: 
      volumes:
      - name: jobservice-config
        configMap:
          name: "release-name-harbor-jobservice"
      - name: job-logs
        persistentVolumeClaim:
          claimName: release-name-harbor-jobservice

---
# Source: harbor/templates/nginx/deployment.yaml

apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: "release-name-harbor-nginx"
  labels:
    app.kubernetes.io/name: "harbor"
    helm.sh/chart: "harbor-3.0.2"
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Tiller
    app.kubernetes.io/component: nginx
spec:
  replicas: 1
  selector:
    matchLabels: 
      app.kubernetes.io/instance: release-name
      app.kubernetes.io/name: "harbor"
      app.kubernetes.io/component: nginx
  template:
    metadata:
      labels:
        
        app.kubernetes.io/name: "harbor"
        helm.sh/chart: "harbor-3.0.2"
        app.kubernetes.io/instance: release-name
        app.kubernetes.io/managed-by: Tiller
        app.kubernetes.io/component: nginx
      annotations:
        sidecar.istio.io/inject: "true"
        checksum/configmap: e97fed9aa9d52b093dccd3060ca61696396c237fcb34556c16eae1e55f5f166d
    spec:      
      securityContext:
        fsGroup: 1000090000
        runAsUser: 1000090000
      containers:
      - name: nginx
        image: "docker.io/bitnami/nginx:1.16.1-debian-9-r92"
        imagePullPolicy: "IfNotPresent"
        livenessProbe:
          httpGet:
            path: /
            port: http
          initialDelaySeconds: 20
          periodSeconds: 10
          timeoutSeconds: 5
          successThreshold: 1
          failureThreshold: 6
        readinessProbe:
          httpGet:
            path: /
            port: http
          initialDelaySeconds: 20
          periodSeconds: 10
          timeoutSeconds: 5
          successThreshold: 1
          failureThreshold: 6
        env:
        - name: BITNAMI_DEBUG
          value: "false"
        ports:
        - containerPort: 8080
          name: http
        - containerPort: 8443
          name: https
        - containerPort: 4443
          name: notary
        volumeMounts:
        - name: config
          mountPath: /opt/bitnami/nginx/conf/nginx.conf
          subPath: nginx.conf
      volumes:
      - name: config
        configMap:
          name: "release-name-harbor-nginx"

---
# Source: harbor/templates/portal/portal-dpl.yaml
apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: "release-name-harbor-portal"
  labels:
    app.kubernetes.io/name: "harbor"
    helm.sh/chart: "harbor-3.0.2"
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Tiller
    app.kubernetes.io/component: portal
spec:
  replicas: 1
  selector:
    matchLabels: 
      app.kubernetes.io/instance: release-name
      app.kubernetes.io/name: "harbor"
      app.kubernetes.io/component: portal
  template:
    metadata:
      labels:
        
        app.kubernetes.io/name: "harbor"
        helm.sh/chart: "harbor-3.0.2"
        app.kubernetes.io/instance: release-name
        app.kubernetes.io/managed-by: Tiller
        app.kubernetes.io/component: portal
      annotations:
        sidecar.istio.io/inject: "true"
    spec:      
      securityContext:
        fsGroup: 1000090000
        runAsUser: 1000090000
      containers:
      - name: portal
        image: "docker.io/bitnami/harbor-portal:1.9.3-ol-7-r28"
        imagePullPolicy: "IfNotPresent"
        livenessProbe:
          httpGet:
            path: /
            port: http
          initialDelaySeconds: 20
          periodSeconds: 10
          timeoutSeconds: 5
          successThreshold: 1
          failureThreshold: 6
        readinessProbe:
          httpGet:
            path: /
            port: http
          initialDelaySeconds: 20
          periodSeconds: 10
          timeoutSeconds: 5
          successThreshold: 1
          failureThreshold: 6
        env:
        - name: BITNAMI_DEBUG
          value: "false"
        ports:
        - containerPort: 8080
          name: http

---
# Source: harbor/templates/registry/registry-dpl.yaml
apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: "release-name-harbor-registry"
  labels:
    app.kubernetes.io/name: "harbor"
    helm.sh/chart: "harbor-3.0.2"
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Tiller
    app.kubernetes.io/component: registry
spec:
  replicas: 1
  selector:
    matchLabels: 
      app.kubernetes.io/instance: release-name
      app.kubernetes.io/name: "harbor"
      app.kubernetes.io/component: registry
  template:
    metadata:
      labels:
        
        app.kubernetes.io/name: "harbor"
        helm.sh/chart: "harbor-3.0.2"
        app.kubernetes.io/instance: release-name
        app.kubernetes.io/managed-by: Tiller
        app.kubernetes.io/component: registry
      annotations:
        sidecar.istio.io/inject: "true"
        checksum/configmap: 336a9e1a1a761be228d7ea630f954d81451f14d5520f01c80dac22063b45ec42
        checksum/secret: 9b710c3889f533ee48fe49930e963839721786ca2683eabf7000beb079d9e23f
        checksum/secret-jobservice: d56a034cbcecb28a7fb3d59f6248e24c8926f4e02d9337d4b5aab496aeb7724e
        checksum/secret-core: 9c5d57436694fb2b3e05ab1ad1188126482f6d4cb88c6b1211866be5032d7632
    spec:      
      securityContext:
        fsGroup: 1000090000
        runAsUser: 1000090000
      containers:
      - name: registry
        image: "docker.io/bitnami/harbor-registry:1.10.0-debian-9-r1"
        imagePullPolicy: "IfNotPresent"
        livenessProbe:
          httpGet:
            path: /
            port: registry
          initialDelaySeconds: 10
          periodSeconds: 10
          timeoutSeconds: 5
          successThreshold: 1
          failureThreshold: 6
        readinessProbe:
          httpGet:
            path: /
            port: registry
          initialDelaySeconds: 10
          periodSeconds: 10
          timeoutSeconds: 5
          successThreshold: 1
          failureThreshold: 6
        env:
        - name: BITNAMI_DEBUG
          value: "false"
        envFrom:
        - secretRef:
            name: "release-name-harbor-registry"
        ports:
        - containerPort: 5000
          name: registry
        - containerPort: 5001
          name: debug
        volumeMounts:
        - name: registry-data
          mountPath: /storage
          subPath: 
        - name: registry-root-certificate
          mountPath: /etc/registry/root.crt
          subPath: tls.crt
        - name: registry-config
          mountPath: /etc/registry/config.yml
          subPath: config.yml
      - name: registryctl
        image: "docker.io/bitnami/harbor-registryctl:1.10.0-debian-9-r1"
        imagePullPolicy: "IfNotPresent"
        livenessProbe:
          httpGet:
            path: /api/health
            port: registryctl
          initialDelaySeconds: 10
          periodSeconds: 10
          timeoutSeconds: 5
          successThreshold: 1
          failureThreshold: 6
        readinessProbe:
          httpGet:
            path: /api/health
            port: registryctl
          initialDelaySeconds: 10
          periodSeconds: 10
          timeoutSeconds: 5
          successThreshold: 1
          failureThreshold: 6
        envFrom:
        - secretRef:
            name: "release-name-harbor-registry"
        env:
        - name: BITNAMI_DEBUG
          value: "false"
        - name: CORE_SECRET
          valueFrom:
            secretKeyRef:
              name: "release-name-harbor-core"
              key: secret
        - name: JOBSERVICE_SECRET
          valueFrom:
            secretKeyRef:
              name: "release-name-harbor-jobservice"
              key: secret
        ports:
        - containerPort: 8080
          name: registryctl
        volumeMounts:
        - name: registry-data
          mountPath: /storage
          subPath: 
        - name: registry-config
          mountPath: /etc/registry/config.yml
          subPath: config.yml
        - name: registry-config
          mountPath: /etc/registryctl/config.yml
          subPath: ctl-config.yml
      volumes:
      - name: registry-root-certificate
        secret:
          secretName: "release-name-harbor-core"
      - name: registry-config
        configMap:
          name: "release-name-harbor-registry"
      - name: registry-data
        persistentVolumeClaim:
          claimName: release-name-harbor-registry

---
# Source: harbor/charts/postgresql/templates/statefulset-slaves.yaml

apiVersion: apps/v1beta2
kind: StatefulSet
metadata:
  name: "release-name-postgresql-slave"
  labels:
    app: postgresql
    chart: postgresql-7.7.3
    release: "release-name"
    heritage: "Tiller"
spec:
  serviceName: release-name-postgresql-headless
  replicas: 1
  selector:
    matchLabels:
      app: postgresql
      release: "release-name"
      role: slave
  template:
    metadata:
      name: release-name-postgresql
      labels:
        app: postgresql
        chart: postgresql-7.7.3
        release: "release-name"
        heritage: "Tiller"
        role: slave
    spec:      
      securityContext:
        fsGroup: 1000090000
      initContainers:
        - name: init-chmod-data
          image: docker.io/bitnami/minideb:stretch
          imagePullPolicy: "Always"
          resources:
            requests:
              cpu: 250m
              memory: 256Mi
            
          command:
            - /bin/sh
            - -c
            - |
              mkdir -p /bitnami/postgresql/data
              chmod 700 /bitnami/postgresql/data
              find /bitnami/postgresql -mindepth 0 -maxdepth 1 -not -name ".snapshot" -not -name "lost+found" | \
                xargs chown -R 1000090000:1000090000
              chmod -R 777 /dev/shm
          securityContext:
            runAsUser: 0
          volumeMounts:
            - name: data
              mountPath: /bitnami/postgresql
              subPath: 
            - name: dshm
              mountPath: /dev/shm
      containers:
        - name: release-name-postgresql
          image: docker.io/bitnami/postgresql:11.6.0-debian-9-r0
          imagePullPolicy: "IfNotPresent"
          resources:
            requests:
              cpu: 250m
              memory: 256Mi
            
          securityContext:
            runAsUser: 1000090000
          env:
            - name: BITNAMI_DEBUG
              value: "false"
            - name: POSTGRESQL_VOLUME_DIR
              value: "/bitnami/postgresql"
            - name: POSTGRESQL_PORT_NUMBER
              value: "5432"
            - name: PGDATA
              value: "/bitnami/postgresql/data"
            - name: POSTGRES_REPLICATION_MODE
              value: "slave"
            - name: POSTGRES_REPLICATION_USER
              value: "repl_user"
            - name: POSTGRES_REPLICATION_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: release-name-postgresql
                  key: postgresql-replication-password
            - name: POSTGRES_CLUSTER_APP_NAME
              value: my_application
            - name: POSTGRES_MASTER_HOST
              value: release-name-postgresql
            - name: POSTGRES_MASTER_PORT_NUMBER
              value: "5432"
            - name: POSTGRES_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: release-name-postgresql
                  key: postgresql-password
          ports:
            - name: postgresql
              containerPort: 5432
          livenessProbe:
            exec:
              command:
                - /bin/sh
                - -c
                - exec pg_isready -U "postgres" -h 127.0.0.1 -p 5432
            initialDelaySeconds: 30
            periodSeconds: 10
            timeoutSeconds: 5
            successThreshold: 1
            failureThreshold: 6
          readinessProbe:
            exec:
              command:
                - /bin/sh
                - -c
                - -e
                - |
                  pg_isready -U "postgres" -h 127.0.0.1 -p 5432
                  [ -f /opt/bitnami/postgresql/tmp/.initialized ]
            initialDelaySeconds: 5
            periodSeconds: 10
            timeoutSeconds: 5
            successThreshold: 1
            failureThreshold: 6
          volumeMounts:
            - name: dshm
              mountPath: /dev/shm
            - name: data
              mountPath: /bitnami/postgresql
              subPath: 
            
      volumes:
        - name: dshm
          emptyDir:
            medium: Memory
            sizeLimit: 1Gi
  updateStrategy:
    type: RollingUpdate
  volumeClaimTemplates:
    - metadata:
        name: data
      spec:
        accessModes:
          - "ReadWriteOnce"
        resources:
          requests:
            storage: "8Gi"
        

---
# Source: harbor/charts/postgresql/templates/statefulset.yaml
apiVersion: apps/v1beta2
kind: StatefulSet
metadata:
  name: release-name-postgresql-master
  labels:
    app: postgresql
    chart: postgresql-7.7.3
    release: "release-name"
    heritage: "Tiller"
spec:
  serviceName: release-name-postgresql-headless
  replicas: 1
  updateStrategy:
    type: RollingUpdate
  selector:
    matchLabels:
      app: postgresql
      release: "release-name"
      role: master
  template:
    metadata:
      name: release-name-postgresql
      labels:
        app: postgresql
        chart: postgresql-7.7.3
        release: "release-name"
        heritage: "Tiller"
        role: master
    spec:      
      securityContext:
        fsGroup: 1000090000
      initContainers:
        - name: init-chmod-data
          image: docker.io/bitnami/minideb:stretch
          imagePullPolicy: "Always"
          resources:
            requests:
              cpu: 250m
              memory: 256Mi
            
          command:
            - /bin/sh
            - -c
            - |
              mkdir -p /bitnami/postgresql/data
              chmod 700 /bitnami/postgresql/data
              find /bitnami/postgresql -mindepth 0 -maxdepth 1 -not -name ".snapshot" -not -name "lost+found" | \
                xargs chown -R 1000090000:1000090000
              chmod -R 777 /dev/shm
          securityContext:
            runAsUser: 0
          volumeMounts:
            - name: data
              mountPath: /bitnami/postgresql
              subPath: 
            - name: dshm
              mountPath: /dev/shm
      containers:
        - name: release-name-postgresql
          image: docker.io/bitnami/postgresql:11.6.0-debian-9-r0
          imagePullPolicy: "IfNotPresent"
          resources:
            requests:
              cpu: 250m
              memory: 256Mi
            
          securityContext:
            runAsUser: 1000090000
          env:
            - name: BITNAMI_DEBUG
              value: "false"
            - name: POSTGRESQL_PORT_NUMBER
              value: "5432"
            - name: POSTGRESQL_VOLUME_DIR
              value: "/bitnami/postgresql"
            - name: PGDATA
              value: "/bitnami/postgresql/data"
            - name: POSTGRES_REPLICATION_MODE
              value: "master"
            - name: POSTGRES_REPLICATION_USER
              value: "repl_user"
            - name: POSTGRES_REPLICATION_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: release-name-postgresql
                  key: postgresql-replication-password
            - name: POSTGRES_CLUSTER_APP_NAME
              value: my_application
            - name: POSTGRES_USER
              value: "postgres"
            - name: POSTGRES_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: release-name-postgresql
                  key: postgresql-password
            - name: POSTGRESQL_ENABLE_LDAP
              value: "no"
          ports:
            - name: postgresql
              containerPort: 5432
          livenessProbe:
            exec:
              command:
                - /bin/sh
                - -c
                - exec pg_isready -U "postgres" -h 127.0.0.1 -p 5432
            initialDelaySeconds: 30
            periodSeconds: 10
            timeoutSeconds: 5
            successThreshold: 1
            failureThreshold: 6
          readinessProbe:
            exec:
              command:
                - /bin/sh
                - -c
                - -e
                - |
                  pg_isready -U "postgres" -h 127.0.0.1 -p 5432
                  [ -f /opt/bitnami/postgresql/tmp/.initialized ]
            initialDelaySeconds: 5
            periodSeconds: 10
            timeoutSeconds: 5
            successThreshold: 1
            failureThreshold: 6
          volumeMounts:
            - name: custom-init-scripts
              mountPath: /docker-entrypoint-initdb.d/
            - name: dshm
              mountPath: /dev/shm
            - name: data
              mountPath: /bitnami/postgresql
              subPath: 
      volumes:
        - name: custom-init-scripts
          configMap:
            name: release-name-postgresql-init-scripts
        - name: dshm
          emptyDir:
            medium: Memory
            sizeLimit: 1Gi
  volumeClaimTemplates:
    - metadata:
        name: data
      spec:
        accessModes:
          - "ReadWriteOnce"
        resources:
          requests:
            storage: "8Gi"
        

---
# Source: harbor/charts/redis/templates/redis-master-statefulset.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: release-name-redis-master
  labels:
    app: redis
    chart: redis-9.5.5
    release: release-name
    heritage: Tiller
spec:
  selector:
    matchLabels:
      app: redis
      release: release-name
      role: master
  serviceName: release-name-redis-headless
  template:
    metadata:
      labels:
        app: redis
        chart: redis-9.5.5
        release: release-name
        role: master
      annotations:
        checksum/health: 30abf82dc50456268b8f608afa93547dac913bc0360dccbce237d57bb9feec89
        checksum/configmap: d11c08e83c96aa5036205b844d25cf17e63b4bb0d1e031adc9dbc6d550afed5f
        checksum/secret: e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855
    spec:      
      securityContext:
        fsGroup: 1.00009e+09
      serviceAccountName: "default"
      containers:
      - name: release-name-redis
        image: "docker.io/bitnami/redis:5.0.7-debian-9-r0"
        imagePullPolicy: "IfNotPresent"
        securityContext:
          runAsUser: 1.00009e+09
        command:
        - /bin/bash
        - -c
        - |
          if [[ -n $REDIS_PASSWORD_FILE ]]; then
            password_aux=`cat ${REDIS_PASSWORD_FILE}`
            export REDIS_PASSWORD=$password_aux
          fi
          if [[ ! -f /opt/bitnami/redis/etc/master.conf ]];then
            cp /opt/bitnami/redis/mounted-etc/master.conf /opt/bitnami/redis/etc/master.conf
          fi
          if [[ ! -f /opt/bitnami/redis/etc/redis.conf ]];then
            cp /opt/bitnami/redis/mounted-etc/redis.conf /opt/bitnami/redis/etc/redis.conf
          fi
          ARGS=("--port" "${REDIS_PORT}")
          ARGS+=("--protected-mode" "no")
          ARGS+=("--include" "/opt/bitnami/redis/etc/redis.conf")
          ARGS+=("--include" "/opt/bitnami/redis/etc/master.conf")
          /run.sh ${ARGS[@]}
        env:
        - name: REDIS_REPLICATION_MODE
          value: master
        - name: ALLOW_EMPTY_PASSWORD
          value: "yes"
        - name: REDIS_PORT
          value: "6379"
        ports:
        - name: redis
          containerPort: 6379
        livenessProbe:
          initialDelaySeconds: 5
          periodSeconds: 5
          timeoutSeconds: 5
          successThreshold: 1
          failureThreshold: 5
          exec:
            command:
            - sh
            - -c
            - /health/ping_liveness_local.sh 5
        readinessProbe:
          initialDelaySeconds: 5
          periodSeconds: 5
          timeoutSeconds: 1
          successThreshold: 1
          failureThreshold: 5
          exec:
            command:
            - sh
            - -c
            - /health/ping_readiness_local.sh 5
        resources:
          null
          
        volumeMounts:
        - name: health
          mountPath: /health
        - name: redis-data
          mountPath: /data
          subPath: 
        - name: config
          mountPath: /opt/bitnami/redis/mounted-etc
        - name: redis-tmp-conf
          mountPath: /opt/bitnami/redis/etc/
      volumes:
      - name: health
        configMap:
          name: release-name-redis-health
          defaultMode: 0755
      - name: config
        configMap:
          name: release-name-redis
      - name: redis-tmp-conf
        emptyDir: {}
  volumeClaimTemplates:
    - metadata:
        name: redis-data
        labels:
          app: redis
          release: release-name
          heritage: Tiller
          component: master
      spec:
        accessModes:
          - "ReadWriteOnce"
        resources:
          requests:
            storage: "8Gi"
        
  updateStrategy:
    type: RollingUpdate

---
# Source: harbor/charts/redis/templates/redis-slave-statefulset.yaml

apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: release-name-redis-slave
  labels:
    app: redis
    chart: redis-9.5.5
    release: release-name
    heritage: Tiller
spec:
  replicas: 2
  serviceName: release-name-redis-headless
  selector:
    matchLabels:
      app: redis
      release: release-name
      role: slave
  template:
    metadata:
      labels:
        app: redis
        release: release-name
        chart: redis-9.5.5
        role: slave
      annotations:
        checksum/health: 30abf82dc50456268b8f608afa93547dac913bc0360dccbce237d57bb9feec89
        checksum/configmap: d11c08e83c96aa5036205b844d25cf17e63b4bb0d1e031adc9dbc6d550afed5f
        checksum/secret: e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855
    spec:      
      securityContext:
        fsGroup: 1.00009e+09
      serviceAccountName: "default"
      containers:
      - name: release-name-redis
        image: docker.io/bitnami/redis:5.0.7-debian-9-r0
        imagePullPolicy: "IfNotPresent"
        securityContext:
          runAsUser: 1.00009e+09
        command:
        - /bin/bash
        - -c
        - |
          if [[ -n $REDIS_PASSWORD_FILE ]]; then
            password_aux=`cat ${REDIS_PASSWORD_FILE}`
            export REDIS_PASSWORD=$password_aux
          fi
          if [[ -n $REDIS_MASTER_PASSWORD_FILE ]]; then
            password_aux=`cat ${REDIS_MASTER_PASSWORD_FILE}`
            export REDIS_MASTER_PASSWORD=$password_aux
          fi
          if [[ ! -f /opt/bitnami/redis/etc/replica.conf ]];then
            cp /opt/bitnami/redis/mounted-etc/replica.conf /opt/bitnami/redis/etc/replica.conf
          fi
          if [[ ! -f /opt/bitnami/redis/etc/redis.conf ]];then
            cp /opt/bitnami/redis/mounted-etc/redis.conf /opt/bitnami/redis/etc/redis.conf
          fi
          ARGS=("--port" "${REDIS_PORT}")
          ARGS+=("--slaveof" "${REDIS_MASTER_HOST}" "${REDIS_MASTER_PORT_NUMBER}")
          ARGS+=("--protected-mode" "no")
          ARGS+=("--include" "/opt/bitnami/redis/etc/redis.conf")
          ARGS+=("--include" "/opt/bitnami/redis/etc/replica.conf")
          /run.sh "${ARGS[@]}"
        env:
        - name: REDIS_REPLICATION_MODE
          value: slave
        - name: REDIS_MASTER_HOST
          value: release-name-redis-master-0.release-name-redis-headless.istio-system.svc.cluster.local
        - name: REDIS_PORT
          value: "6379"
        - name: REDIS_MASTER_PORT_NUMBER
          value: "6379"
        - name: ALLOW_EMPTY_PASSWORD
          value: "yes"
        ports:
        - name: redis
          containerPort: 6379
        livenessProbe:
          initialDelaySeconds: 30
          periodSeconds: 10
          timeoutSeconds: 5
          successThreshold: 1
          failureThreshold: 5
          exec:
            command:
            - sh
            - -c
            - /health/ping_liveness_local_and_master.sh 5
        readinessProbe:
          initialDelaySeconds: 5
          periodSeconds: 10
          timeoutSeconds: 10
          successThreshold: 1
          failureThreshold: 5
          exec:
            command:
            - sh
            - -c
            - /health/ping_readiness_local_and_master.sh 5
        resources:
          null
          
        volumeMounts:
        - name: health
          mountPath: /health
        - name: redis-data
          mountPath: /data
        - name: config
          mountPath: /opt/bitnami/redis/mounted-etc
        - name: redis-tmp-conf
          mountPath: /opt/bitnami/redis/etc
      volumes:
      - name: health
        configMap:
          name: release-name-redis-health
          defaultMode: 0755
      - name: config
        configMap:
          name: release-name-redis
      - name: sentinel-tmp-conf
        emptyDir: {}
      - name: redis-tmp-conf
        emptyDir: {}
  volumeClaimTemplates:
    - metadata:
        name: redis-data
        labels:
          app: redis
          release: release-name
          heritage: Tiller
          component: slave
      spec:
        accessModes:
          - "ReadWriteOnce"
        resources:
          requests:
            storage: "8Gi"
        
  updateStrategy:
    type: RollingUpdate

---
# Source: harbor/templates/nginx/route.yaml
apiVersion: route.openshift.io/v1
kind: Route
metadata:
  labels: 
    app.kubernetes.io/name: "harbor"
    helm.sh/chart: "harbor-3.0.2"
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Tiller
  name: release-name-harbor
spec:
  host: registry.baloise.dev
  path: /
  port:
    targetPort: http
  tls:
    insecureEdgeTerminationPolicy: Redirect
    termination: edge
  to:
    kind: Service
    name: harbor
    weight: 100
  wildcardPolicy: None
status:
  ingress:
    - routerName: router
---
# Source: harbor/charts/postgresql/templates/configmap.yaml


---
# Source: harbor/charts/postgresql/templates/extended-config-configmap.yaml


---
# Source: harbor/charts/postgresql/templates/metrics-configmap.yaml


---
# Source: harbor/charts/postgresql/templates/metrics-svc.yaml


---
# Source: harbor/charts/postgresql/templates/networkpolicy.yaml


---
# Source: harbor/charts/postgresql/templates/prometheusrule.yaml


---
# Source: harbor/charts/postgresql/templates/serviceaccount.yaml

---
# Source: harbor/charts/postgresql/templates/servicemonitor.yaml


---
# Source: harbor/charts/redis/templates/metrics-prometheus.yaml

---
# Source: harbor/charts/redis/templates/metrics-svc.yaml


---
# Source: harbor/charts/redis/templates/networkpolicy.yaml


---
# Source: harbor/charts/redis/templates/psp.yaml


---
# Source: harbor/charts/redis/templates/redis-role.yaml

---
# Source: harbor/charts/redis/templates/redis-rolebinding.yaml

---
# Source: harbor/charts/redis/templates/redis-serviceaccount.yaml

---
# Source: harbor/charts/redis/templates/redis-with-sentinel-svc.yaml


---
# Source: harbor/charts/redis/templates/secret.yaml

---
# Source: harbor/templates/ingress/ingress.yaml


---
# Source: harbor/templates/ingress/secret.yaml

---
# Source: harbor/templates/nginx/configmap-https.yaml


---
# Source: harbor/templates/nginx/secret.yaml

---
# Source: harbor/templates/notary/notary-cm.yaml


---
# Source: harbor/templates/notary/notary-server.yaml


---
# Source: harbor/templates/notary/notary-signer.yaml


---
# Source: harbor/templates/notary/notary-svc.yaml


